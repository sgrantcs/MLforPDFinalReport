{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>leftAnkle_X</th>\n",
       "      <th>leftAnkle_Y</th>\n",
       "      <th>leftAnkle_Z</th>\n",
       "      <th>leftAnkle_Magnitude</th>\n",
       "      <th>Dysk_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429524e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.88235</td>\n",
       "      <td>9.88484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.429524e+09</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>9.72549</td>\n",
       "      <td>9.72549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.429524e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.88235</td>\n",
       "      <td>9.88484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.429524e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.88235</td>\n",
       "      <td>9.88484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429524e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>-0</td>\n",
       "      <td>9.88235</td>\n",
       "      <td>9.8836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     timestamp leftAnkle_X leftAnkle_Y leftAnkle_Z  \\\n",
       "0           0  1.429524e+09    -0.15686    -0.15686     9.88235   \n",
       "1           1  1.429524e+09          -0          -0     9.72549   \n",
       "2           2  1.429524e+09    -0.15686    -0.15686     9.88235   \n",
       "3           3  1.429524e+09    -0.15686    -0.15686     9.88235   \n",
       "4           4  1.429524e+09    -0.15686          -0     9.88235   \n",
       "\n",
       "  leftAnkle_Magnitude  Dysk_Score  \n",
       "0             9.88484           0  \n",
       "1             9.72549           0  \n",
       "2             9.88484           0  \n",
       "3             9.88484           0  \n",
       "4              9.8836           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata_day1 = pd.read_csv(\"./10_BOS_LeftLowerLimb/rawData_Day1_l.csv\")\n",
    "traindata_day1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>leftAnkle_X</th>\n",
       "      <th>leftAnkle_Y</th>\n",
       "      <th>leftAnkle_Z</th>\n",
       "      <th>leftAnkle_Magnitude</th>\n",
       "      <th>Dysk_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429747e+09</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.72549</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>10.08446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.429747e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.72549</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>10.08568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.429747e+09</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.56862</td>\n",
       "      <td>2.66666</td>\n",
       "      <td>9.93450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.429747e+09</td>\n",
       "      <td>-0.31372</td>\n",
       "      <td>9.41177</td>\n",
       "      <td>2.35294</td>\n",
       "      <td>9.70650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.429747e+09</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.56863</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>9.93327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     timestamp  leftAnkle_X  leftAnkle_Y  leftAnkle_Z  \\\n",
       "0           0  1.429747e+09      0.00000      9.72549      2.66667   \n",
       "1           1  1.429747e+09     -0.15686      9.72549      2.66667   \n",
       "2           2  1.429747e+09     -0.15686      9.56862      2.66666   \n",
       "3           3  1.429747e+09     -0.31372      9.41177      2.35294   \n",
       "4           4  1.429747e+09      0.00000      9.56863      2.66667   \n",
       "\n",
       "   leftAnkle_Magnitude  Dysk_Score  \n",
       "0             10.08446           0  \n",
       "1             10.08568           0  \n",
       "2              9.93450           0  \n",
       "3              9.70650           0  \n",
       "4              9.93327           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata_day4 = pd.read_csv(\"./10_BOS_LeftLowerLimb/rawData_Day4_l.csv\")\n",
    "traindata_day4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Patient 10_BOS data for days 1 and 4 to create a single dataframe that will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4717937\n"
     ]
    }
   ],
   "source": [
    "trainingdata = pd.concat([traindata_day1, traindata_day4])\n",
    "print(len(trainingdata))\n",
    "training_labels = trainingdata['Dysk_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = trainingdata[ ['leftAnkle_X', 'leftAnkle_Y','leftAnkle_Z'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>leftAnkle_X</th>\n",
       "      <th>leftAnkle_Y</th>\n",
       "      <th>leftAnkle_Z</th>\n",
       "      <th>leftAnkle_Magnitude</th>\n",
       "      <th>Dysk_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.444037e+09</td>\n",
       "      <td>0.15686</td>\n",
       "      <td>0</td>\n",
       "      <td>9.72549</td>\n",
       "      <td>9.72675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.444037e+09</td>\n",
       "      <td>0.31372</td>\n",
       "      <td>0</td>\n",
       "      <td>9.56863</td>\n",
       "      <td>9.57377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.444037e+09</td>\n",
       "      <td>0.15686</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>9.88235</td>\n",
       "      <td>9.88484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.444037e+09</td>\n",
       "      <td>0.47059</td>\n",
       "      <td>-0.15686</td>\n",
       "      <td>10.0392</td>\n",
       "      <td>10.0515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.444037e+09</td>\n",
       "      <td>0.15686</td>\n",
       "      <td>0.15686</td>\n",
       "      <td>9.56863</td>\n",
       "      <td>9.5712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     timestamp leftAnkle_X leftAnkle_Y leftAnkle_Z  \\\n",
       "0           0  1.444037e+09     0.15686           0     9.72549   \n",
       "1           1  1.444037e+09     0.31372           0     9.56863   \n",
       "2           2  1.444037e+09     0.15686    -0.15686     9.88235   \n",
       "3           3  1.444037e+09     0.47059    -0.15686     10.0392   \n",
       "4           4  1.444037e+09     0.15686     0.15686     9.56863   \n",
       "\n",
       "  leftAnkle_Magnitude  Dysk_Score  \n",
       "0             9.72675           0  \n",
       "1             9.57377           0  \n",
       "2             9.88484           0  \n",
       "3             10.0515           0  \n",
       "4              9.5712           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdata_day1 = pd.read_csv(\"./17_BOS_LeftLowerLimb/rawData_Day1_l.csv\")\n",
    "valdata_day4 = pd.read_csv(\"./17_BOS_LeftLowerLimb/rawData_Day4_l.csv\")\n",
    "valdata_day1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Patient 17_BOS data for days 1 and 4 to create a single dataframe that will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5307298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Dysk_Score, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdata = pd.concat([valdata_day1, valdata_day4])\n",
    "print(len(valdata))\n",
    "val_labels = valdata['Dysk_Score']\n",
    "val_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = valdata[ ['leftAnkle_X', 'leftAnkle_Y','leftAnkle_Z'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, schedules, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very simple model to prototype\n",
    "This is a sequential model, meaning the output of each layer is passed directly into the next one.\n",
    "The first layer is Conv2D: This is a convolutional layer; it directly receives the network’s input, which is a sequence of raw accelerometer data. The input’s shape is provided in the input_shape argument. It’s set to (seq_length, 3, 1), where seq_length is the total number of accelerometer measurements that are passed in (128 by default). Each measurement is composed of three values, representing the x-, y-, and z-axes. \n",
    "The role of the convolutional layer is to take the raw data and extract some basic features that can be interpreted by subsequent layers. The arguments to the Conv2D() function determine how many features will be extracted.\n",
    "The first argument determines how many filters the layer will have. During training, each filter learns to identify a particular feature in the raw data—for example, one filter might learn to identify the signs of an upward motion. For each filter, the layer outputs a feature map that shows where the feature it has learned occurs within the input.\n",
    "The layer defined in the code has 8 filters, meaning that it will learn to recognize and output eight different types of high-level features from the input data. This is reflected in the output shape, (batch_size, 128, 3, 8), which has eight feature channels in its final dimension, one for each feature. The value in each channel indicates the degree to which a feature was present in that location of the input.\n",
    "The convolutional layers slide a window across the data and decide whether a given feature is present in that window. The second argument to Conv2D() is where we provide the dimensions of this window. In our case, it’s (4, 3). This means that the features for which our filters are hunting span four consecutive accelerometer measurements and all three axes. Because the window spans four measurements, each filter analyzes a small snapshot of time, meaning it can generate features that represent a change in acceleration over time. \n",
    "When used for classification, the goal of a CNN is to transform a big, complex input tensor into a small, simple output. This is what the MaxPool2D layer does by congesting the output of the first convolutional layer into a concentrated, high-level representation of the most relevant features it contains. Even though the original input has 3 accelerometer axes for each measurement, a combination of Conv2D and MaxPool2D merges these together into a single value.\n",
    "The Dropout layer randomly sets some of a tensor’s values to zero during training. In this case, by calling Dropout(0.1), we set 10% of the values to zero, entirely obliterating that data. Dropout is a regularization technique and process of improving machine learning models so that they are less likely to overfit their training data. By randomly removing some data between one layer and the next, we force the neural network to learn how to cope with unexpected noise and variation.\n",
    "There can be more Conv2D and MaxPooling layers; let us strat with 2.\n",
    "The Flatten layer is used to transform a multidimensional tensor into one with a single dimension. In this case, our (14, 1, 16) tensor is squished down into a single dimension with shape (224).\n",
    "It’s then fed into a Dense layer with 16 neurons, which considersg all data at once, learning the meanings of various combinations of inputs. The output of this Dense layer will be a set of 16 values representing the content of the original input in a highly compressed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(8, (4,3), activation=tf.nn.relu, padding=\"same\", input_shape=(128,3,1), # output_shape=(batch, 128, 3, 8)),\n",
    "                                    tf.keras.layers.MaxPooling2D(3,3),\n",
    "                                    tf.keras.layers.Dropout(0.1),\n",
    "                                    tf.keras.layers.Conv2D(16, (4,1), activation=tf.nn.relu, padding=\"same\", #input_shape=(42,1,16), # output_shape=(batch, 128, 3, 8)),\n",
    "                                    tf.keras.layers.MaxPooling2D(3,1),\n",
    "                                    tf.keras.layers.Dropout(0.1),\n",
    "                                    tf.keras.layers.Flatten(), # (batch, 224)\n",
    "                                    tf.keras.layers.Dense(16, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 2\n",
    "POOL_SIZE = 2\n",
    "N_FILTERS = 24\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.00001\n",
    "DENSE_UNITS = 50\n",
    "LSTM_UNITS = 50\n",
    "EPOCHS = 100\n",
    "#TO DO: set the right shape\n",
    "N_STEPS = X.shape[1]\n",
    "#N_STEPS = X.shape[1]\n",
    "#TO DO: set the right shape\n",
    "N_FEATURES = (4,)\n",
    "#N_FEATURES = X.shape[4]\n",
    "#this line sets the class weight, which is then stated in the model below. \n",
    "#Need to check what the calculation of the right class weight is. \n",
    "#Should it be based on the share of a class in a training dataset?\n",
    "class_weight = {0: 1., 1: 1/np.mean(training_labels)}\n",
    "\n",
    "ACTIVATION_FUNC = ‘relu’\n",
    "FINAL_ACTIVATION = ‘sigmoid’\n",
    "LOSS_FUNC = ‘binary_crossentropy’\n",
    "METRIC = ‘accuracy’\n",
    "OPTIMIZER = Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add one or more convolutional layers\n",
    "model.add(Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    padding=”same”,\n",
    "    kernel_size=(2,2),\n",
    "    activation=ACTIVATION_FUNC,\n",
    "    input_shape=(N_STEPS, N_FEATURES, 1)),\n",
    ")\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(DENSE_UNITS, activation=ACTIVATION_FUNC))\n",
    "model.add(Dense(1, activation=FINAL_ACTIVATION))\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=LOSS_FUNC,\n",
    "    metrics=[tf.keras.metrics.AUC(), METRIC]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a classifier with multiple classes. Thus, the fitting includes class weights. In most cases, classes are not perfectly balanced, so this addition takes this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "        training_data, training_labels, epochs=EPOCHS,\n",
    "        verbose=1, class_weight=class_weight, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(val_data, val_labels),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
